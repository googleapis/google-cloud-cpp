// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Generated by the Codegen C++ plugin.
// If you make any local changes, they will be lost.
// source: google/ai/generativelanguage/v1/generative_service.proto

#ifndef GOOGLE_CLOUD_CPP_GOOGLE_CLOUD_GENERATIVELANGUAGE_V1_GENERATIVE_CLIENT_H
#define GOOGLE_CLOUD_CPP_GOOGLE_CLOUD_GENERATIVELANGUAGE_V1_GENERATIVE_CLIENT_H

#include "google/cloud/generativelanguage/v1/generative_connection.h"
#include "google/cloud/future.h"
#include "google/cloud/options.h"
#include "google/cloud/polling_policy.h"
#include "google/cloud/status_or.h"
#include "google/cloud/version.h"
#include <memory>
#include <string>

namespace google {
namespace cloud {
namespace generativelanguage_v1 {
GOOGLE_CLOUD_CPP_INLINE_NAMESPACE_BEGIN

///
/// API for using Large Models that generate multimodal content and have
/// additional capabilities beyond text generation.
///
/// @par Equality
///
/// Instances of this class created via copy-construction or copy-assignment
/// always compare equal. Instances created with equal
/// `std::shared_ptr<*Connection>` objects compare equal. Objects that compare
/// equal share the same underlying resources.
///
/// @par Performance
///
/// Creating a new instance of this class is a relatively expensive operation,
/// new objects establish new connections to the service. In contrast,
/// copy-construction, move-construction, and the corresponding assignment
/// operations are relatively efficient as the copies share all underlying
/// resources.
///
/// @par Thread Safety
///
/// Concurrent access to different instances of this class, even if they compare
/// equal, is guaranteed to work. Two or more threads operating on the same
/// instance of this class is not guaranteed to work. Since copy-construction
/// and move-construction is a relatively efficient operation, consider using
/// such a copy when using this class from multiple threads.
///
class GenerativeServiceClient {
 public:
  explicit GenerativeServiceClient(
      std::shared_ptr<GenerativeServiceConnection> connection,
      Options opts = {});
  ~GenerativeServiceClient();

  ///@{
  /// @name Copy and move support
  GenerativeServiceClient(GenerativeServiceClient const&) = default;
  GenerativeServiceClient& operator=(GenerativeServiceClient const&) = default;
  GenerativeServiceClient(GenerativeServiceClient&&) = default;
  GenerativeServiceClient& operator=(GenerativeServiceClient&&) = default;
  ///@}

  ///@{
  /// @name Equality
  friend bool operator==(GenerativeServiceClient const& a,
                         GenerativeServiceClient const& b) {
    return a.connection_ == b.connection_;
  }
  friend bool operator!=(GenerativeServiceClient const& a,
                         GenerativeServiceClient const& b) {
    return !(a == b);
  }
  ///@}

  // clang-format off
  ///
  /// Generates a model response given an input `GenerateContentRequest`.
  /// Refer to the [text generation
  /// guide](https://ai.google.dev/gemini-api/docs/text-generation) for detailed
  /// usage information. Input capabilities differ between models, including
  /// tuned models. Refer to the [model
  /// guide](https://ai.google.dev/gemini-api/docs/models/gemini) and [tuning
  /// guide](https://ai.google.dev/gemini-api/docs/model-tuning) for details.
  ///
  /// @param model  Required. The name of the `Model` to use for generating the completion.
  ///  @n
  ///  Format: `name=models/{model}`.
  /// @param contents  Required. The content of the current conversation with the model.
  ///  @n
  ///  For single-turn queries, this is a single instance. For multi-turn queries
  ///  like [chat](https://ai.google.dev/gemini-api/docs/text-generation#chat),
  ///  this is a repeated field that contains the conversation history and the
  ///  latest request.
  /// @param opts Optional. Override the class-level options, such as retry and
  ///     backoff policies.
  /// @return the result of the RPC. The response message type
  ///     ([google.ai.generativelanguage.v1.GenerateContentResponse])
  ///     is mapped to a C++ class using the [Protobuf mapping rules].
  ///     If the request fails, the [`StatusOr`] contains the error details.
  ///
  /// [Protobuf mapping rules]: https://protobuf.dev/reference/cpp/cpp-generated/
  /// [input iterator requirements]: https://en.cppreference.com/w/cpp/named_req/InputIterator
  /// [`std::string`]: https://en.cppreference.com/w/cpp/string/basic_string
  /// [`future`]: @ref google::cloud::future
  /// [`StatusOr`]: @ref google::cloud::StatusOr
  /// [`Status`]: @ref google::cloud::Status
  /// [google.ai.generativelanguage.v1.GenerateContentRequest]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L132}
  /// [google.ai.generativelanguage.v1.GenerateContentResponse]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L244}
  ///
  // clang-format on
  StatusOr<google::ai::generativelanguage::v1::GenerateContentResponse>
  GenerateContent(
      std::string const& model,
      std::vector<google::ai::generativelanguage::v1::Content> const& contents,
      Options opts = {});

  // clang-format off
  ///
  /// Generates a model response given an input `GenerateContentRequest`.
  /// Refer to the [text generation
  /// guide](https://ai.google.dev/gemini-api/docs/text-generation) for detailed
  /// usage information. Input capabilities differ between models, including
  /// tuned models. Refer to the [model
  /// guide](https://ai.google.dev/gemini-api/docs/models/gemini) and [tuning
  /// guide](https://ai.google.dev/gemini-api/docs/model-tuning) for details.
  ///
  /// @param request Unary RPCs, such as the one wrapped by this
  ///     function, receive a single `request` proto message which includes all
  ///     the inputs for the RPC. In this case, the proto message is a
  ///     [google.ai.generativelanguage.v1.GenerateContentRequest].
  ///     Proto messages are converted to C++ classes by Protobuf, using the
  ///     [Protobuf mapping rules].
  /// @param opts Optional. Override the class-level options, such as retry and
  ///     backoff policies.
  /// @return the result of the RPC. The response message type
  ///     ([google.ai.generativelanguage.v1.GenerateContentResponse])
  ///     is mapped to a C++ class using the [Protobuf mapping rules].
  ///     If the request fails, the [`StatusOr`] contains the error details.
  ///
  /// [Protobuf mapping rules]: https://protobuf.dev/reference/cpp/cpp-generated/
  /// [input iterator requirements]: https://en.cppreference.com/w/cpp/named_req/InputIterator
  /// [`std::string`]: https://en.cppreference.com/w/cpp/string/basic_string
  /// [`future`]: @ref google::cloud::future
  /// [`StatusOr`]: @ref google::cloud::StatusOr
  /// [`Status`]: @ref google::cloud::Status
  /// [google.ai.generativelanguage.v1.GenerateContentRequest]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L132}
  /// [google.ai.generativelanguage.v1.GenerateContentResponse]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L244}
  ///
  // clang-format on
  StatusOr<google::ai::generativelanguage::v1::GenerateContentResponse>
  GenerateContent(
      google::ai::generativelanguage::v1::GenerateContentRequest const& request,
      Options opts = {});

  // clang-format off
  ///
  /// Generates a [streamed
  /// response](https://ai.google.dev/gemini-api/docs/text-generation?lang=python#generate-a-text-stream)
  /// from the model given an input `GenerateContentRequest`.
  ///
  /// @param model  Required. The name of the `Model` to use for generating the completion.
  ///  @n
  ///  Format: `name=models/{model}`.
  /// @param contents  Required. The content of the current conversation with the model.
  ///  @n
  ///  For single-turn queries, this is a single instance. For multi-turn queries
  ///  like [chat](https://ai.google.dev/gemini-api/docs/text-generation#chat),
  ///  this is a repeated field that contains the conversation history and the
  ///  latest request.
  /// @param opts Optional. Override the class-level options, such as retry and
  ///     backoff policies.
  /// @return the result of the RPC. The response message type
  ///     ([google.ai.generativelanguage.v1.GenerateContentResponse])
  ///     is mapped to a C++ class using the [Protobuf mapping rules].
  ///     If the request fails, the [`StatusOr`] contains the error details.
  ///
  /// [Protobuf mapping rules]: https://protobuf.dev/reference/cpp/cpp-generated/
  /// [input iterator requirements]: https://en.cppreference.com/w/cpp/named_req/InputIterator
  /// [`std::string`]: https://en.cppreference.com/w/cpp/string/basic_string
  /// [`future`]: @ref google::cloud::future
  /// [`StatusOr`]: @ref google::cloud::StatusOr
  /// [`Status`]: @ref google::cloud::Status
  /// [google.ai.generativelanguage.v1.GenerateContentRequest]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L132}
  /// [google.ai.generativelanguage.v1.GenerateContentResponse]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L244}
  ///
  // clang-format on
  StreamRange<google::ai::generativelanguage::v1::GenerateContentResponse>
  StreamGenerateContent(
      std::string const& model,
      std::vector<google::ai::generativelanguage::v1::Content> const& contents,
      Options opts = {});

  // clang-format off
  ///
  /// Generates a [streamed
  /// response](https://ai.google.dev/gemini-api/docs/text-generation?lang=python#generate-a-text-stream)
  /// from the model given an input `GenerateContentRequest`.
  ///
  /// @param request Unary RPCs, such as the one wrapped by this
  ///     function, receive a single `request` proto message which includes all
  ///     the inputs for the RPC. In this case, the proto message is a
  ///     [google.ai.generativelanguage.v1.GenerateContentRequest].
  ///     Proto messages are converted to C++ classes by Protobuf, using the
  ///     [Protobuf mapping rules].
  /// @param opts Optional. Override the class-level options, such as retry and
  ///     backoff policies.
  /// @return the result of the RPC. The response message type
  ///     ([google.ai.generativelanguage.v1.GenerateContentResponse])
  ///     is mapped to a C++ class using the [Protobuf mapping rules].
  ///     If the request fails, the [`StatusOr`] contains the error details.
  ///
  /// [Protobuf mapping rules]: https://protobuf.dev/reference/cpp/cpp-generated/
  /// [input iterator requirements]: https://en.cppreference.com/w/cpp/named_req/InputIterator
  /// [`std::string`]: https://en.cppreference.com/w/cpp/string/basic_string
  /// [`future`]: @ref google::cloud::future
  /// [`StatusOr`]: @ref google::cloud::StatusOr
  /// [`Status`]: @ref google::cloud::Status
  /// [google.ai.generativelanguage.v1.GenerateContentRequest]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L132}
  /// [google.ai.generativelanguage.v1.GenerateContentResponse]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L244}
  ///
  // clang-format on
  StreamRange<google::ai::generativelanguage::v1::GenerateContentResponse>
  StreamGenerateContent(
      google::ai::generativelanguage::v1::GenerateContentRequest const& request,
      Options opts = {});

  // clang-format off
  ///
  /// Generates a text embedding vector from the input `Content` using the
  /// specified [Gemini Embedding
  /// model](https://ai.google.dev/gemini-api/docs/models/gemini#text-embedding).
  ///
  /// @param model  Required. The model's resource name. This serves as an ID for the Model to
  ///  use.
  ///  @n
  ///  This name should match a model name returned by the `ListModels` method.
  ///  @n
  ///  Format: `models/{model}`
  /// @param content  Required. The content to embed. Only the `parts.text` fields will be
  ///  counted.
  /// @param opts Optional. Override the class-level options, such as retry and
  ///     backoff policies.
  /// @return the result of the RPC. The response message type
  ///     ([google.ai.generativelanguage.v1.EmbedContentResponse])
  ///     is mapped to a C++ class using the [Protobuf mapping rules].
  ///     If the request fails, the [`StatusOr`] contains the error details.
  ///
  /// [Protobuf mapping rules]: https://protobuf.dev/reference/cpp/cpp-generated/
  /// [input iterator requirements]: https://en.cppreference.com/w/cpp/named_req/InputIterator
  /// [`std::string`]: https://en.cppreference.com/w/cpp/string/basic_string
  /// [`future`]: @ref google::cloud::future
  /// [`StatusOr`]: @ref google::cloud::StatusOr
  /// [`Status`]: @ref google::cloud::Status
  /// [google.ai.generativelanguage.v1.EmbedContentRequest]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L374}
  /// [google.ai.generativelanguage.v1.EmbedContentResponse]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L418}
  ///
  // clang-format on
  StatusOr<google::ai::generativelanguage::v1::EmbedContentResponse>
  EmbedContent(std::string const& model,
               google::ai::generativelanguage::v1::Content const& content,
               Options opts = {});

  // clang-format off
  ///
  /// Generates a text embedding vector from the input `Content` using the
  /// specified [Gemini Embedding
  /// model](https://ai.google.dev/gemini-api/docs/models/gemini#text-embedding).
  ///
  /// @param request Unary RPCs, such as the one wrapped by this
  ///     function, receive a single `request` proto message which includes all
  ///     the inputs for the RPC. In this case, the proto message is a
  ///     [google.ai.generativelanguage.v1.EmbedContentRequest].
  ///     Proto messages are converted to C++ classes by Protobuf, using the
  ///     [Protobuf mapping rules].
  /// @param opts Optional. Override the class-level options, such as retry and
  ///     backoff policies.
  /// @return the result of the RPC. The response message type
  ///     ([google.ai.generativelanguage.v1.EmbedContentResponse])
  ///     is mapped to a C++ class using the [Protobuf mapping rules].
  ///     If the request fails, the [`StatusOr`] contains the error details.
  ///
  /// [Protobuf mapping rules]: https://protobuf.dev/reference/cpp/cpp-generated/
  /// [input iterator requirements]: https://en.cppreference.com/w/cpp/named_req/InputIterator
  /// [`std::string`]: https://en.cppreference.com/w/cpp/string/basic_string
  /// [`future`]: @ref google::cloud::future
  /// [`StatusOr`]: @ref google::cloud::StatusOr
  /// [`Status`]: @ref google::cloud::Status
  /// [google.ai.generativelanguage.v1.EmbedContentRequest]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L374}
  /// [google.ai.generativelanguage.v1.EmbedContentResponse]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L418}
  ///
  // clang-format on
  StatusOr<google::ai::generativelanguage::v1::EmbedContentResponse>
  EmbedContent(
      google::ai::generativelanguage::v1::EmbedContentRequest const& request,
      Options opts = {});

  // clang-format off
  ///
  /// Generates multiple embedding vectors from the input `Content` which
  /// consists of a batch of strings represented as `EmbedContentRequest`
  /// objects.
  ///
  /// @param model  Required. The model's resource name. This serves as an ID for the Model to
  ///  use.
  ///  @n
  ///  This name should match a model name returned by the `ListModels` method.
  ///  @n
  ///  Format: `models/{model}`
  /// @param requests  Required. Embed requests for the batch. The model in each of these requests
  ///  must match the model specified `BatchEmbedContentsRequest.model`.
  /// @param opts Optional. Override the class-level options, such as retry and
  ///     backoff policies.
  /// @return the result of the RPC. The response message type
  ///     ([google.ai.generativelanguage.v1.BatchEmbedContentsResponse])
  ///     is mapped to a C++ class using the [Protobuf mapping rules].
  ///     If the request fails, the [`StatusOr`] contains the error details.
  ///
  /// [Protobuf mapping rules]: https://protobuf.dev/reference/cpp/cpp-generated/
  /// [input iterator requirements]: https://en.cppreference.com/w/cpp/named_req/InputIterator
  /// [`std::string`]: https://en.cppreference.com/w/cpp/string/basic_string
  /// [`future`]: @ref google::cloud::future
  /// [`StatusOr`]: @ref google::cloud::StatusOr
  /// [`Status`]: @ref google::cloud::Status
  /// [google.ai.generativelanguage.v1.BatchEmbedContentsRequest]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L424}
  /// [google.ai.generativelanguage.v1.BatchEmbedContentsResponse]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L445}
  ///
  // clang-format on
  StatusOr<google::ai::generativelanguage::v1::BatchEmbedContentsResponse>
  BatchEmbedContents(
      std::string const& model,
      std::vector<
          google::ai::generativelanguage::v1::EmbedContentRequest> const&
          requests,
      Options opts = {});

  // clang-format off
  ///
  /// Generates multiple embedding vectors from the input `Content` which
  /// consists of a batch of strings represented as `EmbedContentRequest`
  /// objects.
  ///
  /// @param request Unary RPCs, such as the one wrapped by this
  ///     function, receive a single `request` proto message which includes all
  ///     the inputs for the RPC. In this case, the proto message is a
  ///     [google.ai.generativelanguage.v1.BatchEmbedContentsRequest].
  ///     Proto messages are converted to C++ classes by Protobuf, using the
  ///     [Protobuf mapping rules].
  /// @param opts Optional. Override the class-level options, such as retry and
  ///     backoff policies.
  /// @return the result of the RPC. The response message type
  ///     ([google.ai.generativelanguage.v1.BatchEmbedContentsResponse])
  ///     is mapped to a C++ class using the [Protobuf mapping rules].
  ///     If the request fails, the [`StatusOr`] contains the error details.
  ///
  /// [Protobuf mapping rules]: https://protobuf.dev/reference/cpp/cpp-generated/
  /// [input iterator requirements]: https://en.cppreference.com/w/cpp/named_req/InputIterator
  /// [`std::string`]: https://en.cppreference.com/w/cpp/string/basic_string
  /// [`future`]: @ref google::cloud::future
  /// [`StatusOr`]: @ref google::cloud::StatusOr
  /// [`Status`]: @ref google::cloud::Status
  /// [google.ai.generativelanguage.v1.BatchEmbedContentsRequest]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L424}
  /// [google.ai.generativelanguage.v1.BatchEmbedContentsResponse]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L445}
  ///
  // clang-format on
  StatusOr<google::ai::generativelanguage::v1::BatchEmbedContentsResponse>
  BatchEmbedContents(
      google::ai::generativelanguage::v1::BatchEmbedContentsRequest const&
          request,
      Options opts = {});

  // clang-format off
  ///
  /// Runs a model's tokenizer on input `Content` and returns the token count.
  /// Refer to the [tokens guide](https://ai.google.dev/gemini-api/docs/tokens)
  /// to learn more about tokens.
  ///
  /// @param model  Required. The model's resource name. This serves as an ID for the Model to
  ///  use.
  ///  @n
  ///  This name should match a model name returned by the `ListModels` method.
  ///  @n
  ///  Format: `models/{model}`
  /// @param contents  Optional. The input given to the model as a prompt. This field is ignored
  ///  when `generate_content_request` is set.
  /// @param opts Optional. Override the class-level options, such as retry and
  ///     backoff policies.
  /// @return the result of the RPC. The response message type
  ///     ([google.ai.generativelanguage.v1.CountTokensResponse])
  ///     is mapped to a C++ class using the [Protobuf mapping rules].
  ///     If the request fails, the [`StatusOr`] contains the error details.
  ///
  /// [Protobuf mapping rules]: https://protobuf.dev/reference/cpp/cpp-generated/
  /// [input iterator requirements]: https://en.cppreference.com/w/cpp/named_req/InputIterator
  /// [`std::string`]: https://en.cppreference.com/w/cpp/string/basic_string
  /// [`future`]: @ref google::cloud::future
  /// [`StatusOr`]: @ref google::cloud::StatusOr
  /// [`Status`]: @ref google::cloud::Status
  /// [google.ai.generativelanguage.v1.CountTokensRequest]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L456}
  /// [google.ai.generativelanguage.v1.CountTokensResponse]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L489}
  ///
  // clang-format on
  StatusOr<google::ai::generativelanguage::v1::CountTokensResponse> CountTokens(
      std::string const& model,
      std::vector<google::ai::generativelanguage::v1::Content> const& contents,
      Options opts = {});

  // clang-format off
  ///
  /// Runs a model's tokenizer on input `Content` and returns the token count.
  /// Refer to the [tokens guide](https://ai.google.dev/gemini-api/docs/tokens)
  /// to learn more about tokens.
  ///
  /// @param request Unary RPCs, such as the one wrapped by this
  ///     function, receive a single `request` proto message which includes all
  ///     the inputs for the RPC. In this case, the proto message is a
  ///     [google.ai.generativelanguage.v1.CountTokensRequest].
  ///     Proto messages are converted to C++ classes by Protobuf, using the
  ///     [Protobuf mapping rules].
  /// @param opts Optional. Override the class-level options, such as retry and
  ///     backoff policies.
  /// @return the result of the RPC. The response message type
  ///     ([google.ai.generativelanguage.v1.CountTokensResponse])
  ///     is mapped to a C++ class using the [Protobuf mapping rules].
  ///     If the request fails, the [`StatusOr`] contains the error details.
  ///
  /// [Protobuf mapping rules]: https://protobuf.dev/reference/cpp/cpp-generated/
  /// [input iterator requirements]: https://en.cppreference.com/w/cpp/named_req/InputIterator
  /// [`std::string`]: https://en.cppreference.com/w/cpp/string/basic_string
  /// [`future`]: @ref google::cloud::future
  /// [`StatusOr`]: @ref google::cloud::StatusOr
  /// [`Status`]: @ref google::cloud::Status
  /// [google.ai.generativelanguage.v1.CountTokensRequest]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L456}
  /// [google.ai.generativelanguage.v1.CountTokensResponse]: @googleapis_reference_link{google/ai/generativelanguage/v1/generative_service.proto#L489}
  ///
  // clang-format on
  StatusOr<google::ai::generativelanguage::v1::CountTokensResponse> CountTokens(
      google::ai::generativelanguage::v1::CountTokensRequest const& request,
      Options opts = {});

 private:
  std::shared_ptr<GenerativeServiceConnection> connection_;
  Options options_;
};

GOOGLE_CLOUD_CPP_INLINE_NAMESPACE_END
}  // namespace generativelanguage_v1
}  // namespace cloud
}  // namespace google

#endif  // GOOGLE_CLOUD_CPP_GOOGLE_CLOUD_GENERATIVELANGUAGE_V1_GENERATIVE_CLIENT_H
