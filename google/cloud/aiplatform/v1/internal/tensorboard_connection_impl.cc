// Copyright 2023 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Generated by the Codegen C++ plugin.
// If you make any local changes, they will be lost.
// source: google/cloud/aiplatform/v1/tensorboard_service.proto

#include "google/cloud/aiplatform/v1/internal/tensorboard_connection_impl.h"
#include "google/cloud/aiplatform/v1/internal/tensorboard_option_defaults.h"
#include "google/cloud/background_threads.h"
#include "google/cloud/common_options.h"
#include "google/cloud/grpc_options.h"
#include "google/cloud/internal/async_long_running_operation.h"
#include "google/cloud/internal/pagination_range.h"
#include "google/cloud/internal/resumable_streaming_read_rpc.h"
#include "google/cloud/internal/retry_loop.h"
#include "google/cloud/internal/streaming_read_rpc_logging.h"
#include <memory>

namespace google {
namespace cloud {
namespace aiplatform_v1_internal {
GOOGLE_CLOUD_CPP_INLINE_NAMESPACE_BEGIN

TensorboardServiceConnectionImpl::TensorboardServiceConnectionImpl(
    std::unique_ptr<google::cloud::BackgroundThreads> background,
    std::shared_ptr<aiplatform_v1_internal::TensorboardServiceStub> stub,
    Options options)
    : background_(std::move(background)),
      stub_(std::move(stub)),
      options_(internal::MergeOptions(
          std::move(options), TensorboardServiceConnection::options())) {}

future<StatusOr<google::cloud::aiplatform::v1::Tensorboard>>
TensorboardServiceConnectionImpl::CreateTensorboard(
    google::cloud::aiplatform::v1::CreateTensorboardRequest const& request) {
  auto& stub = stub_;
  return google::cloud::internal::AsyncLongRunningOperation<
      google::cloud::aiplatform::v1::Tensorboard>(
      background_->cq(), request,
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::cloud::aiplatform::v1::CreateTensorboardRequest const&
                 request) {
        return stub->AsyncCreateTensorboard(cq, std::move(context), request);
      },
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::longrunning::GetOperationRequest const& request) {
        return stub->AsyncGetOperation(cq, std::move(context), request);
      },
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::longrunning::CancelOperationRequest const& request) {
        return stub->AsyncCancelOperation(cq, std::move(context), request);
      },
      &google::cloud::internal::ExtractLongRunningResultResponse<
          google::cloud::aiplatform::v1::Tensorboard>,
      retry_policy(), backoff_policy(),
      idempotency_policy()->CreateTensorboard(request), polling_policy(),
      __func__);
}

StatusOr<google::cloud::aiplatform::v1::Tensorboard>
TensorboardServiceConnectionImpl::GetTensorboard(
    google::cloud::aiplatform::v1::GetTensorboardRequest const& request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->GetTensorboard(request),
      [this](
          grpc::ClientContext& context,
          google::cloud::aiplatform::v1::GetTensorboardRequest const& request) {
        return stub_->GetTensorboard(context, request);
      },
      request, __func__);
}

future<StatusOr<google::cloud::aiplatform::v1::Tensorboard>>
TensorboardServiceConnectionImpl::UpdateTensorboard(
    google::cloud::aiplatform::v1::UpdateTensorboardRequest const& request) {
  auto& stub = stub_;
  return google::cloud::internal::AsyncLongRunningOperation<
      google::cloud::aiplatform::v1::Tensorboard>(
      background_->cq(), request,
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::cloud::aiplatform::v1::UpdateTensorboardRequest const&
                 request) {
        return stub->AsyncUpdateTensorboard(cq, std::move(context), request);
      },
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::longrunning::GetOperationRequest const& request) {
        return stub->AsyncGetOperation(cq, std::move(context), request);
      },
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::longrunning::CancelOperationRequest const& request) {
        return stub->AsyncCancelOperation(cq, std::move(context), request);
      },
      &google::cloud::internal::ExtractLongRunningResultResponse<
          google::cloud::aiplatform::v1::Tensorboard>,
      retry_policy(), backoff_policy(),
      idempotency_policy()->UpdateTensorboard(request), polling_policy(),
      __func__);
}

StreamRange<google::cloud::aiplatform::v1::Tensorboard>
TensorboardServiceConnectionImpl::ListTensorboards(
    google::cloud::aiplatform::v1::ListTensorboardsRequest request) {
  request.clear_page_token();
  auto& stub = stub_;
  auto retry =
      std::shared_ptr<aiplatform_v1::TensorboardServiceRetryPolicy const>(
          retry_policy());
  auto backoff = std::shared_ptr<BackoffPolicy const>(backoff_policy());
  auto idempotency = idempotency_policy()->ListTensorboards(request);
  char const* function_name = __func__;
  return google::cloud::internal::MakePaginationRange<
      StreamRange<google::cloud::aiplatform::v1::Tensorboard>>(
      std::move(request),
      [stub, retry, backoff, idempotency, function_name](
          google::cloud::aiplatform::v1::ListTensorboardsRequest const& r) {
        return google::cloud::internal::RetryLoop(
            retry->clone(), backoff->clone(), idempotency,
            [stub](grpc::ClientContext& context,
                   google::cloud::aiplatform::v1::ListTensorboardsRequest const&
                       request) {
              return stub->ListTensorboards(context, request);
            },
            r, function_name);
      },
      [](google::cloud::aiplatform::v1::ListTensorboardsResponse r) {
        std::vector<google::cloud::aiplatform::v1::Tensorboard> result(
            r.tensorboards().size());
        auto& messages = *r.mutable_tensorboards();
        std::move(messages.begin(), messages.end(), result.begin());
        return result;
      });
}

future<StatusOr<google::cloud::aiplatform::v1::DeleteOperationMetadata>>
TensorboardServiceConnectionImpl::DeleteTensorboard(
    google::cloud::aiplatform::v1::DeleteTensorboardRequest const& request) {
  auto& stub = stub_;
  return google::cloud::internal::AsyncLongRunningOperation<
      google::cloud::aiplatform::v1::DeleteOperationMetadata>(
      background_->cq(), request,
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::cloud::aiplatform::v1::DeleteTensorboardRequest const&
                 request) {
        return stub->AsyncDeleteTensorboard(cq, std::move(context), request);
      },
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::longrunning::GetOperationRequest const& request) {
        return stub->AsyncGetOperation(cq, std::move(context), request);
      },
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::longrunning::CancelOperationRequest const& request) {
        return stub->AsyncCancelOperation(cq, std::move(context), request);
      },
      &google::cloud::internal::ExtractLongRunningResultMetadata<
          google::cloud::aiplatform::v1::DeleteOperationMetadata>,
      retry_policy(), backoff_policy(),
      idempotency_policy()->DeleteTensorboard(request), polling_policy(),
      __func__);
}

StatusOr<google::cloud::aiplatform::v1::ReadTensorboardUsageResponse>
TensorboardServiceConnectionImpl::ReadTensorboardUsage(
    google::cloud::aiplatform::v1::ReadTensorboardUsageRequest const& request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->ReadTensorboardUsage(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::ReadTensorboardUsageRequest const&
                 request) {
        return stub_->ReadTensorboardUsage(context, request);
      },
      request, __func__);
}

StatusOr<google::cloud::aiplatform::v1::TensorboardExperiment>
TensorboardServiceConnectionImpl::CreateTensorboardExperiment(
    google::cloud::aiplatform::v1::CreateTensorboardExperimentRequest const&
        request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->CreateTensorboardExperiment(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::
                 CreateTensorboardExperimentRequest const& request) {
        return stub_->CreateTensorboardExperiment(context, request);
      },
      request, __func__);
}

StatusOr<google::cloud::aiplatform::v1::TensorboardExperiment>
TensorboardServiceConnectionImpl::GetTensorboardExperiment(
    google::cloud::aiplatform::v1::GetTensorboardExperimentRequest const&
        request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->GetTensorboardExperiment(request),
      [this](
          grpc::ClientContext& context,
          google::cloud::aiplatform::v1::GetTensorboardExperimentRequest const&
              request) {
        return stub_->GetTensorboardExperiment(context, request);
      },
      request, __func__);
}

StatusOr<google::cloud::aiplatform::v1::TensorboardExperiment>
TensorboardServiceConnectionImpl::UpdateTensorboardExperiment(
    google::cloud::aiplatform::v1::UpdateTensorboardExperimentRequest const&
        request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->UpdateTensorboardExperiment(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::
                 UpdateTensorboardExperimentRequest const& request) {
        return stub_->UpdateTensorboardExperiment(context, request);
      },
      request, __func__);
}

StreamRange<google::cloud::aiplatform::v1::TensorboardExperiment>
TensorboardServiceConnectionImpl::ListTensorboardExperiments(
    google::cloud::aiplatform::v1::ListTensorboardExperimentsRequest request) {
  request.clear_page_token();
  auto& stub = stub_;
  auto retry =
      std::shared_ptr<aiplatform_v1::TensorboardServiceRetryPolicy const>(
          retry_policy());
  auto backoff = std::shared_ptr<BackoffPolicy const>(backoff_policy());
  auto idempotency = idempotency_policy()->ListTensorboardExperiments(request);
  char const* function_name = __func__;
  return google::cloud::internal::MakePaginationRange<
      StreamRange<google::cloud::aiplatform::v1::TensorboardExperiment>>(
      std::move(request),
      [stub, retry, backoff, idempotency,
       function_name](google::cloud::aiplatform::v1::
                          ListTensorboardExperimentsRequest const& r) {
        return google::cloud::internal::RetryLoop(
            retry->clone(), backoff->clone(), idempotency,
            [stub](grpc::ClientContext& context,
                   google::cloud::aiplatform::v1::
                       ListTensorboardExperimentsRequest const& request) {
              return stub->ListTensorboardExperiments(context, request);
            },
            r, function_name);
      },
      [](google::cloud::aiplatform::v1::ListTensorboardExperimentsResponse r) {
        std::vector<google::cloud::aiplatform::v1::TensorboardExperiment>
            result(r.tensorboard_experiments().size());
        auto& messages = *r.mutable_tensorboard_experiments();
        std::move(messages.begin(), messages.end(), result.begin());
        return result;
      });
}

future<StatusOr<google::cloud::aiplatform::v1::DeleteOperationMetadata>>
TensorboardServiceConnectionImpl::DeleteTensorboardExperiment(
    google::cloud::aiplatform::v1::DeleteTensorboardExperimentRequest const&
        request) {
  auto& stub = stub_;
  return google::cloud::internal::AsyncLongRunningOperation<
      google::cloud::aiplatform::v1::DeleteOperationMetadata>(
      background_->cq(), request,
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::cloud::aiplatform::v1::
                 DeleteTensorboardExperimentRequest const& request) {
        return stub->AsyncDeleteTensorboardExperiment(cq, std::move(context),
                                                      request);
      },
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::longrunning::GetOperationRequest const& request) {
        return stub->AsyncGetOperation(cq, std::move(context), request);
      },
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::longrunning::CancelOperationRequest const& request) {
        return stub->AsyncCancelOperation(cq, std::move(context), request);
      },
      &google::cloud::internal::ExtractLongRunningResultMetadata<
          google::cloud::aiplatform::v1::DeleteOperationMetadata>,
      retry_policy(), backoff_policy(),
      idempotency_policy()->DeleteTensorboardExperiment(request),
      polling_policy(), __func__);
}

StatusOr<google::cloud::aiplatform::v1::TensorboardRun>
TensorboardServiceConnectionImpl::CreateTensorboardRun(
    google::cloud::aiplatform::v1::CreateTensorboardRunRequest const& request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->CreateTensorboardRun(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::CreateTensorboardRunRequest const&
                 request) {
        return stub_->CreateTensorboardRun(context, request);
      },
      request, __func__);
}

StatusOr<google::cloud::aiplatform::v1::BatchCreateTensorboardRunsResponse>
TensorboardServiceConnectionImpl::BatchCreateTensorboardRuns(
    google::cloud::aiplatform::v1::BatchCreateTensorboardRunsRequest const&
        request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->BatchCreateTensorboardRuns(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::
                 BatchCreateTensorboardRunsRequest const& request) {
        return stub_->BatchCreateTensorboardRuns(context, request);
      },
      request, __func__);
}

StatusOr<google::cloud::aiplatform::v1::TensorboardRun>
TensorboardServiceConnectionImpl::GetTensorboardRun(
    google::cloud::aiplatform::v1::GetTensorboardRunRequest const& request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->GetTensorboardRun(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::GetTensorboardRunRequest const&
                 request) {
        return stub_->GetTensorboardRun(context, request);
      },
      request, __func__);
}

StatusOr<google::cloud::aiplatform::v1::TensorboardRun>
TensorboardServiceConnectionImpl::UpdateTensorboardRun(
    google::cloud::aiplatform::v1::UpdateTensorboardRunRequest const& request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->UpdateTensorboardRun(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::UpdateTensorboardRunRequest const&
                 request) {
        return stub_->UpdateTensorboardRun(context, request);
      },
      request, __func__);
}

StreamRange<google::cloud::aiplatform::v1::TensorboardRun>
TensorboardServiceConnectionImpl::ListTensorboardRuns(
    google::cloud::aiplatform::v1::ListTensorboardRunsRequest request) {
  request.clear_page_token();
  auto& stub = stub_;
  auto retry =
      std::shared_ptr<aiplatform_v1::TensorboardServiceRetryPolicy const>(
          retry_policy());
  auto backoff = std::shared_ptr<BackoffPolicy const>(backoff_policy());
  auto idempotency = idempotency_policy()->ListTensorboardRuns(request);
  char const* function_name = __func__;
  return google::cloud::internal::MakePaginationRange<
      StreamRange<google::cloud::aiplatform::v1::TensorboardRun>>(
      std::move(request),
      [stub, retry, backoff, idempotency, function_name](
          google::cloud::aiplatform::v1::ListTensorboardRunsRequest const& r) {
        return google::cloud::internal::RetryLoop(
            retry->clone(), backoff->clone(), idempotency,
            [stub](
                grpc::ClientContext& context,
                google::cloud::aiplatform::v1::ListTensorboardRunsRequest const&
                    request) {
              return stub->ListTensorboardRuns(context, request);
            },
            r, function_name);
      },
      [](google::cloud::aiplatform::v1::ListTensorboardRunsResponse r) {
        std::vector<google::cloud::aiplatform::v1::TensorboardRun> result(
            r.tensorboard_runs().size());
        auto& messages = *r.mutable_tensorboard_runs();
        std::move(messages.begin(), messages.end(), result.begin());
        return result;
      });
}

future<StatusOr<google::cloud::aiplatform::v1::DeleteOperationMetadata>>
TensorboardServiceConnectionImpl::DeleteTensorboardRun(
    google::cloud::aiplatform::v1::DeleteTensorboardRunRequest const& request) {
  auto& stub = stub_;
  return google::cloud::internal::AsyncLongRunningOperation<
      google::cloud::aiplatform::v1::DeleteOperationMetadata>(
      background_->cq(), request,
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::cloud::aiplatform::v1::DeleteTensorboardRunRequest const&
                 request) {
        return stub->AsyncDeleteTensorboardRun(cq, std::move(context), request);
      },
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::longrunning::GetOperationRequest const& request) {
        return stub->AsyncGetOperation(cq, std::move(context), request);
      },
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::longrunning::CancelOperationRequest const& request) {
        return stub->AsyncCancelOperation(cq, std::move(context), request);
      },
      &google::cloud::internal::ExtractLongRunningResultMetadata<
          google::cloud::aiplatform::v1::DeleteOperationMetadata>,
      retry_policy(), backoff_policy(),
      idempotency_policy()->DeleteTensorboardRun(request), polling_policy(),
      __func__);
}

StatusOr<
    google::cloud::aiplatform::v1::BatchCreateTensorboardTimeSeriesResponse>
TensorboardServiceConnectionImpl::BatchCreateTensorboardTimeSeries(
    google::cloud::aiplatform::v1::
        BatchCreateTensorboardTimeSeriesRequest const& request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->BatchCreateTensorboardTimeSeries(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::
                 BatchCreateTensorboardTimeSeriesRequest const& request) {
        return stub_->BatchCreateTensorboardTimeSeries(context, request);
      },
      request, __func__);
}

StatusOr<google::cloud::aiplatform::v1::TensorboardTimeSeries>
TensorboardServiceConnectionImpl::CreateTensorboardTimeSeries(
    google::cloud::aiplatform::v1::CreateTensorboardTimeSeriesRequest const&
        request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->CreateTensorboardTimeSeries(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::
                 CreateTensorboardTimeSeriesRequest const& request) {
        return stub_->CreateTensorboardTimeSeries(context, request);
      },
      request, __func__);
}

StatusOr<google::cloud::aiplatform::v1::TensorboardTimeSeries>
TensorboardServiceConnectionImpl::GetTensorboardTimeSeries(
    google::cloud::aiplatform::v1::GetTensorboardTimeSeriesRequest const&
        request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->GetTensorboardTimeSeries(request),
      [this](
          grpc::ClientContext& context,
          google::cloud::aiplatform::v1::GetTensorboardTimeSeriesRequest const&
              request) {
        return stub_->GetTensorboardTimeSeries(context, request);
      },
      request, __func__);
}

StatusOr<google::cloud::aiplatform::v1::TensorboardTimeSeries>
TensorboardServiceConnectionImpl::UpdateTensorboardTimeSeries(
    google::cloud::aiplatform::v1::UpdateTensorboardTimeSeriesRequest const&
        request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->UpdateTensorboardTimeSeries(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::
                 UpdateTensorboardTimeSeriesRequest const& request) {
        return stub_->UpdateTensorboardTimeSeries(context, request);
      },
      request, __func__);
}

StreamRange<google::cloud::aiplatform::v1::TensorboardTimeSeries>
TensorboardServiceConnectionImpl::ListTensorboardTimeSeries(
    google::cloud::aiplatform::v1::ListTensorboardTimeSeriesRequest request) {
  request.clear_page_token();
  auto& stub = stub_;
  auto retry =
      std::shared_ptr<aiplatform_v1::TensorboardServiceRetryPolicy const>(
          retry_policy());
  auto backoff = std::shared_ptr<BackoffPolicy const>(backoff_policy());
  auto idempotency = idempotency_policy()->ListTensorboardTimeSeries(request);
  char const* function_name = __func__;
  return google::cloud::internal::MakePaginationRange<
      StreamRange<google::cloud::aiplatform::v1::TensorboardTimeSeries>>(
      std::move(request),
      [stub, retry, backoff, idempotency, function_name](
          google::cloud::aiplatform::v1::ListTensorboardTimeSeriesRequest const&
              r) {
        return google::cloud::internal::RetryLoop(
            retry->clone(), backoff->clone(), idempotency,
            [stub](grpc::ClientContext& context,
                   google::cloud::aiplatform::v1::
                       ListTensorboardTimeSeriesRequest const& request) {
              return stub->ListTensorboardTimeSeries(context, request);
            },
            r, function_name);
      },
      [](google::cloud::aiplatform::v1::ListTensorboardTimeSeriesResponse r) {
        std::vector<google::cloud::aiplatform::v1::TensorboardTimeSeries>
            result(r.tensorboard_time_series().size());
        auto& messages = *r.mutable_tensorboard_time_series();
        std::move(messages.begin(), messages.end(), result.begin());
        return result;
      });
}

future<StatusOr<google::cloud::aiplatform::v1::DeleteOperationMetadata>>
TensorboardServiceConnectionImpl::DeleteTensorboardTimeSeries(
    google::cloud::aiplatform::v1::DeleteTensorboardTimeSeriesRequest const&
        request) {
  auto& stub = stub_;
  return google::cloud::internal::AsyncLongRunningOperation<
      google::cloud::aiplatform::v1::DeleteOperationMetadata>(
      background_->cq(), request,
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::cloud::aiplatform::v1::
                 DeleteTensorboardTimeSeriesRequest const& request) {
        return stub->AsyncDeleteTensorboardTimeSeries(cq, std::move(context),
                                                      request);
      },
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::longrunning::GetOperationRequest const& request) {
        return stub->AsyncGetOperation(cq, std::move(context), request);
      },
      [stub](google::cloud::CompletionQueue& cq,
             std::shared_ptr<grpc::ClientContext> context,
             google::longrunning::CancelOperationRequest const& request) {
        return stub->AsyncCancelOperation(cq, std::move(context), request);
      },
      &google::cloud::internal::ExtractLongRunningResultMetadata<
          google::cloud::aiplatform::v1::DeleteOperationMetadata>,
      retry_policy(), backoff_policy(),
      idempotency_policy()->DeleteTensorboardTimeSeries(request),
      polling_policy(), __func__);
}

StatusOr<
    google::cloud::aiplatform::v1::BatchReadTensorboardTimeSeriesDataResponse>
TensorboardServiceConnectionImpl::BatchReadTensorboardTimeSeriesData(
    google::cloud::aiplatform::v1::
        BatchReadTensorboardTimeSeriesDataRequest const& request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->BatchReadTensorboardTimeSeriesData(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::
                 BatchReadTensorboardTimeSeriesDataRequest const& request) {
        return stub_->BatchReadTensorboardTimeSeriesData(context, request);
      },
      request, __func__);
}

StatusOr<google::cloud::aiplatform::v1::ReadTensorboardTimeSeriesDataResponse>
TensorboardServiceConnectionImpl::ReadTensorboardTimeSeriesData(
    google::cloud::aiplatform::v1::ReadTensorboardTimeSeriesDataRequest const&
        request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->ReadTensorboardTimeSeriesData(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::
                 ReadTensorboardTimeSeriesDataRequest const& request) {
        return stub_->ReadTensorboardTimeSeriesData(context, request);
      },
      request, __func__);
}

StreamRange<google::cloud::aiplatform::v1::ReadTensorboardBlobDataResponse>
TensorboardServiceConnectionImpl::ReadTensorboardBlobData(
    google::cloud::aiplatform::v1::ReadTensorboardBlobDataRequest const&
        request) {
  auto& stub = stub_;
  auto retry =
      std::shared_ptr<aiplatform_v1::TensorboardServiceRetryPolicy const>(
          retry_policy());
  auto backoff = std::shared_ptr<BackoffPolicy const>(backoff_policy());

  auto factory =
      [stub](
          google::cloud::aiplatform::v1::ReadTensorboardBlobDataRequest const&
              request) {
        return stub->ReadTensorboardBlobData(
            std::make_shared<grpc::ClientContext>(), request);
      };
  auto resumable = internal::MakeResumableStreamingReadRpc<
      google::cloud::aiplatform::v1::ReadTensorboardBlobDataResponse,
      google::cloud::aiplatform::v1::ReadTensorboardBlobDataRequest>(
      retry->clone(), backoff->clone(), [](std::chrono::milliseconds) {},
      factory, TensorboardServiceReadTensorboardBlobDataStreamingUpdater,
      request);
  return internal::MakeStreamRange(
      internal::StreamReader<
          google::cloud::aiplatform::v1::ReadTensorboardBlobDataResponse>(
          [resumable] { return resumable->Read(); }));
}
StatusOr<google::cloud::aiplatform::v1::WriteTensorboardExperimentDataResponse>
TensorboardServiceConnectionImpl::WriteTensorboardExperimentData(
    google::cloud::aiplatform::v1::WriteTensorboardExperimentDataRequest const&
        request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->WriteTensorboardExperimentData(request),
      [this](grpc::ClientContext& context,
             google::cloud::aiplatform::v1::
                 WriteTensorboardExperimentDataRequest const& request) {
        return stub_->WriteTensorboardExperimentData(context, request);
      },
      request, __func__);
}

StatusOr<google::cloud::aiplatform::v1::WriteTensorboardRunDataResponse>
TensorboardServiceConnectionImpl::WriteTensorboardRunData(
    google::cloud::aiplatform::v1::WriteTensorboardRunDataRequest const&
        request) {
  return google::cloud::internal::RetryLoop(
      retry_policy(), backoff_policy(),
      idempotency_policy()->WriteTensorboardRunData(request),
      [this](
          grpc::ClientContext& context,
          google::cloud::aiplatform::v1::WriteTensorboardRunDataRequest const&
              request) {
        return stub_->WriteTensorboardRunData(context, request);
      },
      request, __func__);
}

StreamRange<google::cloud::aiplatform::v1::TimeSeriesDataPoint>
TensorboardServiceConnectionImpl::ExportTensorboardTimeSeriesData(
    google::cloud::aiplatform::v1::ExportTensorboardTimeSeriesDataRequest
        request) {
  request.clear_page_token();
  auto& stub = stub_;
  auto retry =
      std::shared_ptr<aiplatform_v1::TensorboardServiceRetryPolicy const>(
          retry_policy());
  auto backoff = std::shared_ptr<BackoffPolicy const>(backoff_policy());
  auto idempotency =
      idempotency_policy()->ExportTensorboardTimeSeriesData(request);
  char const* function_name = __func__;
  return google::cloud::internal::MakePaginationRange<
      StreamRange<google::cloud::aiplatform::v1::TimeSeriesDataPoint>>(
      std::move(request),
      [stub, retry, backoff, idempotency,
       function_name](google::cloud::aiplatform::v1::
                          ExportTensorboardTimeSeriesDataRequest const& r) {
        return google::cloud::internal::RetryLoop(
            retry->clone(), backoff->clone(), idempotency,
            [stub](grpc::ClientContext& context,
                   google::cloud::aiplatform::v1::
                       ExportTensorboardTimeSeriesDataRequest const& request) {
              return stub->ExportTensorboardTimeSeriesData(context, request);
            },
            r, function_name);
      },
      [](google::cloud::aiplatform::v1::ExportTensorboardTimeSeriesDataResponse
             r) {
        std::vector<google::cloud::aiplatform::v1::TimeSeriesDataPoint> result(
            r.time_series_data_points().size());
        auto& messages = *r.mutable_time_series_data_points();
        std::move(messages.begin(), messages.end(), result.begin());
        return result;
      });
}

GOOGLE_CLOUD_CPP_INLINE_NAMESPACE_END
}  // namespace aiplatform_v1_internal
}  // namespace cloud
}  // namespace google
